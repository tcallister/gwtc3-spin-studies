{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c17ec86f-c1c3-4b48-a215-b4437c4be3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('plotting.mplstyle')\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append('./../code/emceeCode')\n",
    "from posterior_helper_functions import *\n",
    "from downsample_sampleDict import downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0323e880-be97-4976-b354-7bca6cab24c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2647)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ada61-bf83-46e8-af54-a490db35a3b8",
   "metadata": {},
   "source": [
    "Calculate effective samples for `betaSpikePlusTruncatedMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c260427f-d516-4d05-ac36-2c5277d32375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sampleDict\n",
    "sampleDict_all = np.load(\"../code/input/sampleDict_FAR_1_in_1_yr.pickle\", allow_pickle=True)\n",
    "\n",
    "# Get rid of non BBH events\n",
    "non_BBHs = ['GW170817','S190425z','S190426c','S190814bv','S190917u','S200105ae','S200115j']\n",
    "for event in non_BBHs:\n",
    "    sampleDict_all.pop(event)\n",
    "\n",
    "# Downsample individuale event posteriors to match the input to emcee\n",
    "events_more = [ # events that we want more samples for -- see downsample documentation\n",
    "    'S191109d', 'S191103a', 'S190728q', 'GW170729', 'S190519bj', 'S190620e', \n",
    "    'S190805bq', 'S190517h', 'S190412m', 'GW151226', 'S191204r', 'S190719an', \n",
    "    'S190521g', 'S191127p', 'S200128d', 'S190706ai', 'S190720a', 'S190929d', \n",
    "    'S190527w', 'S200225q', 'S200129m', 'S191216ap', 'S190828j', 'S200216br', \n",
    "    'S190602aq', 'S200224ca', 'S190925ad', 'S200209ab'\n",
    "]\n",
    "sampleDict = downsample(sampleDict_all, events_more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f69e81ed-8066-4cca-ba87-bf83592f5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hyperparameter samples\n",
    "with open('../data/component_spin_betaSpikePlusTruncatedMixture.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "230f1013-80a0-49d8-8ca9-40cdf669a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict in which to store the effective samples\n",
    "Neff_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5abed9-4fb6-41d6-a781-0f539ed479ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total number of hyperparameters for betaSpikePlusTruncatedMixture model\n",
    "nHyperParams = len(data['mu_chi']['processed'])\n",
    "\n",
    "# cycle through events\n",
    "for event in sampleDict: \n",
    "    \n",
    "    print('Calculating Neffs for', event)\n",
    "    \n",
    "    # Fetch samples\n",
    "    chi1_samples = sampleDict[event]['a1']\n",
    "    chi2_samples =  sampleDict[event]['a2']\n",
    "    cost1_samples = sampleDict[event]['cost1']\n",
    "    cost2_samples = sampleDict[event]['cost2']\n",
    "    \n",
    "    # Set up data structures in which to store Neff info\n",
    "    Neffs_total = np.zeros(nHyperParams)\n",
    "    Neffs_justSpike = np.zeros(nHyperParams)\n",
    "    Neffs_justBulk = np.zeros(nHyperParams)\n",
    "\n",
    "    for i in np.arange(nHyperParams):\n",
    "\n",
    "        # Unpack parameter\n",
    "        mu_chi = data['mu_chi']['processed'][i]\n",
    "        sigma_chi = data['sigma_chi']['processed'][i]\n",
    "        MF_cost = data['MF_cost']['processed'][i]\n",
    "        sigma_cost = data['sigma_cost']['processed'][i]\n",
    "        frac_in_spike = data['frac_in_spike']['processed'][i]\n",
    "        sigma_spike = data['sigma_spike']['processed'][i]\n",
    "        cost_min = data['cost_min']['processed'][i]\n",
    "        \n",
    "        a, b = mu_sigma2_to_a_b(mu_chi, sigma_chi**2.)\n",
    "\n",
    "        # Evaluate model at the locations of our samples\n",
    "        beta_chi1 = betaDistribution(chi1_samples, a, b)\n",
    "        spike_chi1 = calculate_Gaussian_1D(chi1_samples, 0, sigma_spike, 0., 1.)\n",
    "        p_chi1 = frac_in_spike*spike_chi1 + (1-frac_in_spike)*beta_chi1\n",
    "\n",
    "        beta_chi2 = betaDistribution(chi2_samples, a, b)\n",
    "        spike_chi2 = calculate_Gaussian_1D(chi2_samples, 0, sigma_spike, 0., 1.)\n",
    "        p_chi2 = frac_in_spike*spike_chi2 + (1-frac_in_spike)*beta_chi2\n",
    "\n",
    "        p_cost1 = calculate_Gaussian_Mixture_1D(cost1_samples, 1, sigma_cost, MF_cost, cost_min, 1.)\n",
    "        p_cost2 = calculate_Gaussian_Mixture_1D(cost2_samples, 1, sigma_cost, MF_cost, cost_min, 1.)\n",
    "\n",
    "        # Calculate effective number of samples for different parts of the distribution\n",
    "        det_weights_total = p_chi1*p_chi1*p_cost1*p_cost2\n",
    "        det_weights_spike = spike_chi1*spike_chi2*p_cost1*p_cost2\n",
    "        det_weights_bulk = beta_chi1*beta_chi2*p_cost1*p_cost2\n",
    "        \n",
    "        # add to arrays\n",
    "        Neffs_total[i] = np.sum(det_weights_total)**2/np.sum(det_weights_total**2)\n",
    "        Neffs_justSpike[i] = np.sum(det_weights_spike)**2/np.sum(det_weights_spike**2)\n",
    "        Neffs_justBulk[i] = np.sum(det_weights_bulk)**2/np.sum(det_weights_bulk**2)\n",
    "        \n",
    "    Neff_dict[event] = {\n",
    "        'total':Neffs_total, \n",
    "        'spike':Neffs_justSpike, \n",
    "        'bulk':Neffs_justBulk\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd3d2d-4b97-4b41-9385-667369ddaa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save because these calculations take a while\n",
    "np.save('figure_08_Neff_dict.npy', Neff_dict, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d414f51a-9dae-44cd-8a71-310a97851dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in results 3x for the 3 different cases we care about\n",
    "# (will get rid of events from Neff_dict_no_def_spinning and Neff_dict_no_likely_spinning)\n",
    "Neff_dict_all = np.load('figure_08_Neff_dict.npy', allow_pickle=True).reshape(1)[0]\n",
    "Neff_dict_no_def_spinning = np.load('figure_08_Neff_dict.npy', allow_pickle=True).reshape(1)[0]\n",
    "Neff_dict_no_likely_spinning = np.load('figure_08_Neff_dict.npy', allow_pickle=True).reshape(1)[0]\n",
    "\n",
    "# get mins across all events\n",
    "min_Neffs_total = np.min([Neff_dict_all[event]['total'] for event in Neff_dict_all], axis=0)\n",
    "min_Neffs_bulk = np.min([Neff_dict_all[event]['bulk'] for event in Neff_dict_all], axis=0)\n",
    "min_Neffs_spike = np.min([Neff_dict_all[event]['spike'] for event in Neff_dict_all], axis=0)\n",
    "\n",
    "# get rid of \"definitely spinning\" events \n",
    "Neff_dict_no_def_spinning.pop('S190517h')\n",
    "Neff_dict_no_def_spinning.pop('S190412m')\n",
    "Neff_dict_no_def_spinning.pop('GW151226')\n",
    "Neff_dict_no_def_spinning.pop('S191204r')\n",
    "min_Neffs_spike_no_def_spinning = np.min([Neff_dict_no_def_spinning[event]['spike'] for event in Neff_dict_no_def_spinning], axis=0)\n",
    "\n",
    "# get rid of \"likely spinning\" events\n",
    "for event in Neff_dict_all: \n",
    "    a1_samps = sampleDict[event]['a1']\n",
    "    a2_samps = sampleDict[event]['a2']\n",
    "    if len(a1_samps[(a1_samps<=0.1)*(a2_samps<=0.1)]) < len(a1_samps)/200.: \n",
    "        print(event)\n",
    "        Neff_dict_no_likely_spinning.pop(event)\n",
    "min_Neffs_spike_no_likely_spinning = np.min([Neff_dict_no_likely_spinning[event]['spike'] for event in Neff_dict_no_likely_spinning], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964a65a-ed7a-4aa6-96b4-473ad2de237e",
   "metadata": {},
   "source": [
    "Make figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb75be-478d-4e3f-a1f4-f121f3ad7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_spikes = data['sigma_spike']['processed']\n",
    "\n",
    "titles = [r'Total Distribution', r'Just bulk', r'Just spike']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 4.5), sharey=True, sharex=True)\n",
    "\n",
    "# for total and bulk \n",
    "for i, ax, min_Neffs, title in zip(range(3), axes, [min_Neffs_total, min_Neffs_bulk, min_Neffs_spike],titles): \n",
    "    \n",
    "    ax.set_rasterization_zorder(2)\n",
    "    \n",
    "    if i!=2:\n",
    "        ax.scatter(epsilon_spikes, np.log10(min_Neffs), s=7, zorder=1)\n",
    "    \n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlim(0.02, 0.1)\n",
    "    ax.set_ylim(-0.1, 3.4)\n",
    "\n",
    "# for spike, each of the 3 cases     \n",
    "axes[-1].scatter(epsilon_spikes, np.log10(min_Neffs_spike), s=7, zorder=1, label='All events')\n",
    "axes[-1].scatter(epsilon_spikes, np.log10(min_Neffs_spike_no_def_spinning), s=7, zorder=1, color='red', label='Excluding confidently spinning')\n",
    "axes[-1].scatter(epsilon_spikes, np.log10(min_Neffs_spike_no_likely_spinning), s=7, zorder=1, color='C2', label='Excluding likely spinning')\n",
    "\n",
    "axes[1].set_xlabel(r'$\\epsilon_\\mathrm{spike}$')\n",
    "axes[0].set_ylabel(r'min $\\log_{10}[N_{\\mathrm{eff},i}]$')\n",
    "\n",
    "# legend\n",
    "axes[-1].legend(loc='upper right', fontsize=14, frameon=True)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.11)\n",
    "plt.savefig('figure_08.pdf', bbox_inches='tight', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c6a7e0-b2af-4991-adf1-25fc2dee0098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igwn-py38",
   "language": "python",
   "name": "igwn-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
